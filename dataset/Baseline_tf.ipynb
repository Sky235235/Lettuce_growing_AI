{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'/mnt/d/데이터분석/Dacon/Lettuce_growing_AI'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/mnt/d/데이터분석/Dacon/Lettuce_growing_AI\")\n",
    "project_path = os.getcwd()\n",
    "\n",
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyper Parameter Setting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS' : 100,\n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'BATCH_SIZE': 16,\n",
    "    'SEED':2358\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "all_input_list = sorted(glob.glob('dataset/train_input/*.csv'))\n",
    "all_target_list = sorted(glob.glob('dataset/train_target/*.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습: 25, 검증:3\n"
     ]
    }
   ],
   "source": [
    "train_input_list = all_input_list[:25]\n",
    "train_target_list = all_target_list[:25]\n",
    "\n",
    "val_input_list = all_input_list[25:]\n",
    "val_target_list = all_target_list[25:]\n",
    "\n",
    "print(f'학습: {len(train_input_list)}, 검증:{len(val_input_list)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CustomDataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_paths, target_paths, batch_size, infer_mode, shuffle=False):\n",
    "        self.input_paths = input_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.infer_mode = infer_mode\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.data_list = []\n",
    "        self.label_list = []\n",
    "        print('Data Pre-processing..')\n",
    "        for input_path, target_path in tqdm(zip(self.input_paths, self.target_paths)):\n",
    "            input_df = pd.read_csv(input_path)\n",
    "            target_df = pd.read_csv(target_path)\n",
    "\n",
    "            input_df = input_df.drop(columns=['obs_time'])\n",
    "            input_df = input_df.fillna(0)\n",
    "\n",
    "\n",
    "            target_length = int(len(target_df))\n",
    "\n",
    "            for idx in range(target_length):\n",
    "                time_series = input_df[24*idx:24*(idx+1)].values\n",
    "                self.data_list.append(time_series)\n",
    "\n",
    "            for label in target_df['predicted_weight_g']:\n",
    "                self.label_list.append(label)\n",
    "        print('Done. \\n')\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.data_list)/self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "\n",
    "        data = [self.data_list[i] for i in indices]\n",
    "        label = [self.label_list[i] for i in indices]\n",
    "\n",
    "        if self.infer_mode == False:\n",
    "            return tf.convert_to_tensor(data), tf.convert_to_tensor(label)\n",
    "        else:\n",
    "            return tf.convert_to_tensor(data)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.data_list))\n",
    "\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pre-processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 37.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. \n",
      "\n",
      "Data Pre-processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 54.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = Dataloader(train_input_list, train_target_list, CFG['BATCH_SIZE'], False, shuffle=True)\n",
    "val_loader = Dataloader(val_input_list, val_target_list, CFG['BATCH_SIZE'], False, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Define"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class BaseModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.lstm = tf.keras.layers.LSTM(256)\n",
    "        self.classifier = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h = self.lstm(inputs)\n",
    "        return self.classifier(h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 2s 19ms/step - loss: 34.4708 - val_loss: 20.7735 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 32.6110 - val_loss: 19.6794 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 31.6620 - val_loss: 19.1235 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 31.1956 - val_loss: 18.9961 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 30.7154 - val_loss: 18.8460 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 30.3798 - val_loss: 18.8525 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 30.1452 - val_loss: 18.7819 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.9910 - val_loss: 18.6940 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.8845 - val_loss: 18.6279 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.7378 - val_loss: 18.4629 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.6349 - val_loss: 18.5700 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 29.3984\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.5253 - val_loss: 18.4971 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.4440 - val_loss: 18.5193 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.3663 - val_loss: 18.4171 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.2167 - val_loss: 18.4242 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 29.0923 - val_loss: 18.1799 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 28.9435 - val_loss: 18.1034 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 28.8266 - val_loss: 18.0161 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 28.6640 - val_loss: 17.5455 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 28.5047 - val_loss: 17.3514 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 28.3011 - val_loss: 17.4619 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 28.3558 - val_loss: 17.1000 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 28.3313 - val_loss: 17.2020 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 27.9618 - val_loss: 16.7957 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 27.6764 - val_loss: 16.2341 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 27.4612 - val_loss: 16.2889 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 27.2741 - val_loss: 16.0968 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 27.3929 - val_loss: 15.7467 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 27.1378 - val_loss: 15.3449 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.9775 - val_loss: 15.3627 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 26.0955\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.6998 - val_loss: 15.6124 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.5854 - val_loss: 15.1805 - lr: 2.5000e-04\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.4944 - val_loss: 15.3167 - lr: 2.5000e-04\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.3150 - val_loss: 14.7556 - lr: 2.5000e-04\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.3193 - val_loss: 14.7371 - lr: 2.5000e-04\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.1164 - val_loss: 14.8478 - lr: 2.5000e-04\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.0445 - val_loss: 14.4908 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 26.0086 - val_loss: 14.5872 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.8826 - val_loss: 14.4891 - lr: 2.5000e-04\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.8026 - val_loss: 14.4573 - lr: 2.5000e-04\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.8244 - val_loss: 14.3956 - lr: 2.5000e-04\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.6730 - val_loss: 14.3209 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.7340 - val_loss: 14.8205 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.7070 - val_loss: 14.2680 - lr: 2.5000e-04\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.5283 - val_loss: 14.0922 - lr: 2.5000e-04\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.3988 - val_loss: 14.1785 - lr: 2.5000e-04\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.4137 - val_loss: 14.0689 - lr: 2.5000e-04\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.3337 - val_loss: 14.0353 - lr: 2.5000e-04\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.3004 - val_loss: 14.2162 - lr: 2.5000e-04\n",
      "Epoch 50/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.9463\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.2359 - val_loss: 14.1886 - lr: 2.5000e-04\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.1396 - val_loss: 14.0113 - lr: 1.2500e-04\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.0817 - val_loss: 13.8588 - lr: 1.2500e-04\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.0469 - val_loss: 13.8458 - lr: 1.2500e-04\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 25.0223 - val_loss: 13.8860 - lr: 1.2500e-04\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.9850 - val_loss: 13.8360 - lr: 1.2500e-04\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 1s 17ms/step - loss: 24.9654 - val_loss: 13.9008 - lr: 1.2500e-04\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.9173 - val_loss: 13.8042 - lr: 1.2500e-04\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.8751 - val_loss: 13.5979 - lr: 1.2500e-04\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.8952 - val_loss: 13.5807 - lr: 1.2500e-04\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.8257 - val_loss: 13.6728 - lr: 1.2500e-04\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.7780 - val_loss: 13.5800 - lr: 1.2500e-04\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.8548 - val_loss: 13.4341 - lr: 1.2500e-04\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 24.7139 - val_loss: 13.4736 - lr: 1.2500e-04\n",
      "Epoch 64/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.5714\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 24.6430 - val_loss: 13.5268 - lr: 1.2500e-04\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 24.6393 - val_loss: 13.4023 - lr: 6.2500e-05\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.5646 - val_loss: 13.4397 - lr: 6.2500e-05\n",
      "Epoch 67/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.4963\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.5483 - val_loss: 13.5078 - lr: 6.2500e-05\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.5179 - val_loss: 13.4660 - lr: 3.1250e-05\n",
      "Epoch 69/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.2342\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4913 - val_loss: 13.4682 - lr: 3.1250e-05\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4797 - val_loss: 13.4680 - lr: 1.5625e-05\n",
      "Epoch 71/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.0253\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4659 - val_loss: 13.4688 - lr: 1.5625e-05\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4560 - val_loss: 13.4629 - lr: 7.8125e-06\n",
      "Epoch 73/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.1369\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4514 - val_loss: 13.4640 - lr: 7.8125e-06\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4477 - val_loss: 13.4633 - lr: 3.9063e-06\n",
      "Epoch 75/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 23.9024\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4467 - val_loss: 13.4677 - lr: 3.9063e-06\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4446 - val_loss: 13.4660 - lr: 1.9531e-06\n",
      "Epoch 77/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.6835\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4430 - val_loss: 13.4638 - lr: 1.9531e-06\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4417 - val_loss: 13.4643 - lr: 9.7656e-07\n",
      "Epoch 79/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.7086\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4415 - val_loss: 13.4652 - lr: 9.7656e-07\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4408 - val_loss: 13.4647 - lr: 4.8828e-07\n",
      "Epoch 81/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 25.0274\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4405 - val_loss: 13.4652 - lr: 4.8828e-07\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4401 - val_loss: 13.4653 - lr: 2.4414e-07\n",
      "Epoch 83/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.0440\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4402 - val_loss: 13.4651 - lr: 2.4414e-07\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4399 - val_loss: 13.4652 - lr: 1.2207e-07\n",
      "Epoch 85/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.8821\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4399 - val_loss: 13.4653 - lr: 1.2207e-07\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4398 - val_loss: 13.4653 - lr: 6.1035e-08\n",
      "Epoch 87/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.3022\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4398 - val_loss: 13.4654 - lr: 6.1035e-08\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4654 - lr: 3.0518e-08\n",
      "Epoch 89/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 24.3865\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4654 - lr: 3.0518e-08\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4654 - lr: 1.5259e-08\n",
      "Epoch 91/100\n",
      "41/44 [==========================>...] - ETA: 0s - loss: 25.1219\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4654 - lr: 1.5259e-08\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4654 - lr: 1.0000e-08\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4654 - lr: 1.0000e-08\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4654 - lr: 1.0000e-08\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4654 - lr: 1.0000e-08\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4655 - lr: 1.0000e-08\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4655 - lr: 1.0000e-08\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4655 - lr: 1.0000e-08\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4655 - lr: 1.0000e-08\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 24.4397 - val_loss: 13.4655 - lr: 1.0000e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fc769f6f610>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaseModel()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=CFG['LEARNING_RATE']),\n",
    "    loss=tf.keras.losses.MeanAbsoluteError()\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_loader, validation_data=val_loader,\n",
    "    epochs=CFG['EPOCHS'],\n",
    "    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-8, verbose=1)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test_input_list = sorted(glob.glob('dataset/test_input/*.csv'))\n",
    "test_target_list = sorted(glob.glob('dataset/test_target/*.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/test_target/TEST_01.csv\n",
      "Data Pre-processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "dataset/test_target/TEST_02.csv\n",
      "Data Pre-processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 34.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. \n",
      "\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/test_target/TEST_03.csv\n",
      "Data Pre-processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 71.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. \n",
      "\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/test_target/TEST_04.csv\n",
      "Data Pre-processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 36.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "dataset/test_target/TEST_05.csv\n",
      "Data Pre-processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 37.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. \n",
      "\n",
      "1/2 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "for test_input_path, test_target_path in zip(test_input_list, test_target_list):\n",
    "    print(test_target_path)\n",
    "    test_loader = Dataloader([test_input_path], [test_target_path], CFG['BATCH_SIZE'], True, shuffle=False)\n",
    "    model_pred = model.predict(test_loader)\n",
    "\n",
    "    submit_df = pd.read_csv(test_target_path)\n",
    "    submit_df['predicted_weight_g'] = model_pred\n",
    "    submit_df.to_csv(test_target_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import zipfile\n",
    "# os.chdir(\"dataset/test_target/\")\n",
    "submission = zipfile.ZipFile(\"submission.zip\", 'w')\n",
    "for path in test_target_list:\n",
    "    path = path.split('/')[-1]\n",
    "    submission.write(path)\n",
    "submission.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'/mnt/d/데이터분석/Dacon/Lettuce_growing_AI/dataset/test_target'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}